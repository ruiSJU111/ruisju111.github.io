
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Module 1: Introduction to Computer Vision</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 40px; }
        h1, h2 { color: #2c3e50; }
        pre { background-color: #f4f4f4; padding: 10px; border-left: 3px solid #ccc; overflow-x: auto; }
        .box { border: 1px solid #ccc; padding: 20px; background: #f9f9f9; margin: 20px 0; }
        ul { margin-top: 0; }
    </style>
</head>
<body>
    <h1>Module 1: Introduction to Computer Vision</h1>

    <h2>1. What is Computer Vision?</h2>
    <p><strong>Definition:</strong> Computer Vision is the field of study focused on enabling machines to process and interpret visual information from the world, similar to how humans do using their vision system.</p>
    <ul>
        <li>It enables automated tasks such as detection, classification, tracking, and recognition.</li>
        <li>Often powered by deep learning and image processing techniques.</li>
        <li>Used in diverse domains: healthcare, security, retail, robotics, and self-driving cars.</li>
    </ul>

    <h2>2. Key Concepts and Components</h2>
    <ul>
        <li><strong>Pixels:</strong> Smallest unit of an image; each pixel contains intensity/color information.</li>
        <li><strong>Color spaces:</strong> RGB, HSV, Grayscale - various ways to represent color information.</li>
        <li><strong>Image formats:</strong> JPG, PNG, TIFF - impact quality, compression, and storage.</li>
        <li><strong>Resolution:</strong> The number of pixels in width and height of the image.</li>
    </ul>

    <h2>3. Applications of Computer Vision</h2>
    <ul>
        <li>Autonomous Driving (lane and object detection)</li>
        <li>Medical Imaging (e.g., tumor detection, retinal scan analysis)</li>
        <li>Surveillance (e.g., person tracking, facial recognition)</li>
        <li>Retail (e.g., customer counting, shelf monitoring)</li>
        <li>OCR and historical document digitization</li>
    </ul>

    <h2>4. Image Understanding vs Image Processing</h2>
    <p><strong>Image Processing:</strong> Basic transformations to improve or analyze an image (e.g., filters, enhancement).</p>
    <p><strong>Image Understanding:</strong> Extracting semantic meaning from visual data (e.g., classifying an image as a cat).</p>
    <pre>Image Processing → Feature Extraction → Image Understanding</pre>

    <h2>5. Basic Equation of Image Formation</h2>
    <pre>
g(x, y) = f(x, y) * h(x, y) + n(x, y)

Where:
    - f(x, y): original image (ideal signal)
    - h(x, y): point spread function (camera optics)
    - n(x, y): additive noise
    - g(x, y): observed image captured by camera
    </pre>
    <p>This equation is a basic model for how digital images are formed considering system imperfections.</p>

    <h2>6. Visual Perception Pipeline</h2>
    <div class="box">
        <p><strong>Diagram (conceptual):</strong></p>
        <p>Scene → Camera Sensor → Digital Image → Preprocessing → Feature Extraction → Inference → Output</p>
    </div>

    <h2>7. Real-World Example: Autonomous Vehicles</h2>
    <p>Self-driving cars use computer vision to interpret their surroundings.</p>
    <ul>
        <li>Input: Real-time camera feed from road</li>
        <li>CV Tasks: Detect lanes, traffic signs, pedestrians</li>
        <li>Output: Decisions for navigation, braking, or acceleration</li>
    </ul>

    <h2>8. Timeline of Key Milestones</h2>
    <ul>
        <li><strong>1960s–80s:</strong> Rule-based and symbolic vision (edge detection, Hough transform)</li>
        <li><strong>1990s:</strong> Hand-crafted features (SIFT, SURF, HOG)</li>
        <li><strong>2012:</strong> Deep learning revolution (AlexNet on ImageNet)</li>
        <li><strong>Now:</strong> Transformers, self-supervised learning, multimodal vision</li>
    </ul>

    <h2>9. Hands-on Practice (Colab Compatible)</h2>
    <p>OpenCV Canny Edge Detection on a user-uploaded image:</p>
    <pre><code>!pip install opencv-python-headless matplotlib

import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
from google.colab import files

uploaded = files.upload()
img_path = next(iter(uploaded))

# Load and show original
img = cv2.imread(img_path)
cv2_imshow(img)

# Convert to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
cv2_imshow(gray)

# Gaussian blur
blur = cv2.GaussianBlur(gray, (5, 5), 0)

# Canny edge detection
edges = cv2.Canny(blur, 100, 200)
cv2_imshow(edges)

cv2.imwrite("canny_edges.jpg", edges)
    </code></pre>

    <h2>10. Assignment</h2>
    <div class="box">
        <p><strong>Objective:</strong> Understand foundational CV concepts, run code, and reflect on vision applications.</p>
        <ul>
            <li>1. Write a 1-page summary: What is computer vision?</li>
            <li>2. List and describe 3 real-world applications of CV</li>
            <li>3. Run the edge detection code and upload your image + results</li>
            <li>4. (Optional) Sketch and explain a vision pipeline</li>
        </ul>
        <p><strong>Due:</strong> End of Week 1</p>
    </div>

</body>
</html>
